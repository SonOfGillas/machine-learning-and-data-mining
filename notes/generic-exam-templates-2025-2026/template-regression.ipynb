{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d753a310",
   "metadata": {},
   "source": [
    "# Template Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random_state = 67\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29242ec2",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26750af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "url = ''\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the distribution of the target variable\n",
    "# count help to see if there are some missing values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592abd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n rows with missing values\n",
    "df.shape[0]-df.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values per columns\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of the features\n",
    "# check for outliers and different scales of the features\n",
    "df.boxplot(figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fcd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature correlation, is expecially usefull see the correlation with the target feature\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7360210",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91497ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null rows\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) If there is a string variable, we need to encode it to numerical values \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "column_to_transform = ''\n",
    "df[column_to_transform] = le.fit_transform(df[column_to_transform].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) use this to convert nominal labels to numerical values\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one = OneHotEncoder()\n",
    "column_to_transform = 'exemple_column'\n",
    "enc_data = one.fit_transform(df[column_to_transform].values)\n",
    "l = list(one.categories_[0])\n",
    "enc_df = pd.DataFrame(enc_data.toarray(),columns=l)\n",
    "df = df.join(enc_df)\n",
    "df = df.drop([column_to_transform],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) use this to convert ordinal labels to numerical values\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "categories = ['bad','good','very good'] # exemple of ordinal categories\n",
    "oe = OrdinalEncoder(categories=categories,dtype=int)\n",
    "column_to_transform = 'col_name'\n",
    "df[column_to_transform] = oe.fit_transform(df[column_to_transform].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the ranges of the features to be between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_processed = pd.DataFrame(scaler.fit_transform(df),columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data standardization\n",
    "from sklearn.preprocessing import PowerTransformer,StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "preprocessor = make_pipeline(PowerTransformer(),StandardScaler())\n",
    "df_processed = pd.DataFrame(preprocessor.fit_transform(df),columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0341602",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ''\n",
    "X = df.drop(target,axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19b3abb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43291d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=random_state, train_size=0.7 )\n",
    "print(f'train size {X_train.shape[0]}, test size {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45482195",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Model','RMSE','R_square'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7694768",
   "metadata": {},
   "source": [
    "### Univariate Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the feature that has the hiest correlation with the target\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,root_mean_squared_error\n",
    "\n",
    "feature_selected = 'F1'\n",
    "X_train_univariate = X_train[feature_selected].values.reshape(-1,1)\n",
    "X_test_univariate = X_test[feature_selected].values.reshape(-1,1)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_univariate,y_train)\n",
    "y_pred_univariate = lr.predict(X_test_univariate)\n",
    "\n",
    "# regression function\n",
    "coeff_univariate = lr.coef_[0] # Coefficient of the feature\n",
    "intercept_univariate = lr.intercept_ # Bias\n",
    "\n",
    "results.loc[len(results)] = [\n",
    "    f'Linear Univariate on {feature_selected}',\n",
    "    root_mean_squared_error(y_test,y_pred_univariate),\n",
    "    r2_score(y_test,y_pred_univariate)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d54227",
   "metadata": {},
   "source": [
    "### Multivariate Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e690cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred_multivariate = lr.predict(X_test)\n",
    "\n",
    "# regression function\n",
    "coeff_multivariate = lr.coef_ # Coefficient of the feature\n",
    "intercept_multivariate = lr.intercept_ # Bias\n",
    "\n",
    "results.loc[len(results)] = [\n",
    "    f'Linear Multivariate',\n",
    "    mean_squared_error(y_test,y_pred_multivariate),\n",
    "    r2_score(y_test,y_pred_multivariate)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9dcc57",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f624389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Max Depth of the tree by running the algorithm normally\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=random_state)\n",
    "dt.fit(X_train,y_train)\n",
    "max_depth = dt.tree_.max_dept\n",
    "print(\"The maximum depth of the full Decision Tree Regressor is {}\".format(max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefa181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Search the Best tree depth with cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "paramGrid = {'max_depth':[*range(1,max_depth+1)]}\n",
    "\n",
    "dt_gscv = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(random_state=random_state),\n",
    "    param_grid=paramGrid,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "dt_gscv.fit(X_train,y_train)\n",
    "dt_best = dt_gscv.best_estimator_\n",
    "best_max_depth = dt_best.tree_.max_dept\n",
    "print(\"The optimal maximum depth for the decision tree is {}\".format(best_max_depth))\n",
    "\n",
    "y_pred_dt = dt_best.predict(X_test)\n",
    "results.loc[len(results)] = [\n",
    "    f'Decision Tree',\n",
    "    mean_squared_error(y_test,y_pred_dt),\n",
    "    r2_score(y_test,y_pred_dt)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e33ad5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abe303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=random_state)\n",
    "param_grid_rf = {'max_depth':list(range(1,max_depth+1))}\n",
    "\n",
    "rf_gscv = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ")\n",
    "rf_gscv.fit(X_train,y_train)\n",
    "rf = rf_gscv.best_estimator_\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "results.loc[len(results)] = [\n",
    "    f'Random Forest',\n",
    "    mean_squared_error(y_test,y_pred_rf),\n",
    "    r2_score(y_test,y_pred_rf)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f20a6",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "degrees = list(range(2,5))\n",
    "for degree in degrees:\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    \n",
    "    lr_poly = LinearRegression()\n",
    "    lr_poly.fit(X_train_poly,y_train)\n",
    "    y_pred_poly = lr_poly.predict(X_test_poly)\n",
    "    \n",
    "    results.loc[len(results)] = [\n",
    "        f'Polynomial Regression degree {degree}',\n",
    "        mean_squared_error(y_test,y_pred_poly),\n",
    "        r2_score(y_test,y_pred_poly)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2881efd",
   "metadata": {},
   "source": [
    "## Display Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Decision Tree\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize = (20,15))\n",
    "plot_tree(dt_best,\n",
    "          feature_names=X.columns.to_list(),\n",
    "          filled=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38417d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "# we can plot only one feature, so we choose the one with the highest correlation with the target\n",
    "feature_to_plot = 'F1'\n",
    "\n",
    "# we need to sort the feature for incrising value to have a nice plot.\n",
    "# and for that reason when need to sort also the corresponding predictions.\n",
    "plot_df = pd.DataFrame()\n",
    "plot_df[feature_to_plot] = X_test[feature_to_plot]\n",
    "plot_df['y_test'] = y_test\n",
    "plot_df['y_pred_univariate'] = y_pred_univariate\n",
    "plot_df['y_pred_multivariate'] = y_pred_multivariate\n",
    "plot_df['y_pred_dt'] = y_pred_dt\n",
    "plot_df['y_pred_rf'] = y_pred_rf\n",
    "plot_df = plot_df.sort_values(by=feature_to_plot)\n",
    "\n",
    "# Plot the true values and the predictions of the different models\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(plot_df[feature_to_plot],plot_df['y_test'],label='True Values',color='black')\n",
    "plt.plot(plot_df[feature_to_plot],plot_df['y_pred_univariate'],label='Linear Univariate',color='blue')\n",
    "plt.plot(plot_df[feature_to_plot],plot_df['y_pred_multivariate'],label='Linear Multivariate',color='orange')\n",
    "plt.plot(plot_df[feature_to_plot],plot_df['y_pred_dt'],label='Decision Tree',color='green')\n",
    "plt.plot(plot_df[feature_to_plot],plot_df['y_pred_rf'],label='Random Forest',color='red')\n",
    "plt.xlabel(feature_to_plot)\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b6bc6",
   "metadata": {},
   "source": [
    "Other accuracy measures: F_test, P score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the professor did this in lab but never explained F_test in therory only P Score\n",
    "import scipy.stats\n",
    "\n",
    "# Exemple of callinf f_test ->  f_test(y, y_pred, X.shape[1], X.shape[0])\n",
    "def f_test(y_true, y_pred, n_var, n_obs):\n",
    "    \"\"\" Computation of F-statistic and p-value for the regression\n",
    "    http://facweb.cs.depaul.edu/sjost/csc423/documents/f-test-reg.htm\n",
    "    Requires: np (numpy) and scipy.stats\n",
    "\n",
    "    Arguments:\n",
    "    y_true: ground truth\n",
    "    y_pred: predictions\n",
    "    n_var: number of predicting variables\n",
    "    n_obs: number of observations (the length of y_true and y_pred)\n",
    "\n",
    "    Returns:\n",
    "    F: F statistics\n",
    "    p: p-value\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    n = n_obs\n",
    "    p = n_var+1 # number of regression parameters (coefficients + intercept)\n",
    "    y_true_m = np.mean(y_true)\n",
    "    SSM = np.sum((y_pred-y_true_m)**2)\n",
    "    SSE = np.sum((y_true-y_pred)**2)\n",
    "    DFM = p - 1 # degrees of freedom for model - numerator\n",
    "    DFE = n - p # degrees of freedom for error - denominator\n",
    "    MSM = SSM / DFM\n",
    "    MSE = SSE / DFE\n",
    "    F = MSM / MSE\n",
    "    # f = np.var(x, ddof=1)/np.var(y, ddof=1) #calculate F test statistic\n",
    "    p = 1-scipy.stats.f.cdf(F, DFM, DFE) #find p-value of F test statistic\n",
    "    return F, p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDM2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
