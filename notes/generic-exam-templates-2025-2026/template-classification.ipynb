{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371e1e4b",
   "metadata": {},
   "source": [
    "# Classification Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb2b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "train_size = 0.67\n",
    "cv_splits = StratifiedGroupKFold(n_splits=3,shuffle=True)\n",
    "randomState = 42\n",
    "np.random.seed(randomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18703372",
   "metadata": {},
   "source": [
    "## Esplore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'\n",
    "url = ''\n",
    "df = pd.read_csv(url)  #delimiter=, index_col=, names=\n",
    "\n",
    "# Check the number of samples and the number of features\n",
    "print(f' Data frame has {df.shape[0]} samples, and {df.shape[1]-1} features ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558103a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the distribution of the target variable\n",
    "# count help to see if there are some missing values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ea3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n rows with missing values\n",
    "df.shape[0]-df.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values per columns\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4016d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize target class distribution / class umbalanced\n",
    "df[target].value_counts().sort_index().plot(kind='bar',rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the distribution of the features\n",
    "# check for outliers\n",
    "df.boxplot(figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ee450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the relationship between features and target variable\n",
    "# and for linear relationship between features\n",
    "sns.pairplot(df,hue=target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7de8ef",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'there are {df.isna().sum().sum()} rows with null values')\n",
    "df1 = df.dropna()\n",
    "print(f'there are {df1.isna().sum().sum()} rows with null values')\n",
    "print(f'Data frame has {df1.shape[0]} samples, and {df1.shape[1]-1} features ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data frame in X features and target\n",
    "X = df1.drop([target],axis=1)\n",
    "y = df1[target]\n",
    "\n",
    "print(f'X shape {X.shape}')\n",
    "print(f'y shape {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef97d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) If there is a string variable, we need to encode it to numerical values \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "column_to_transform = 'target'\n",
    "transofermed_column = le.fit_transform(df1[column_to_transform])\n",
    "df1[column_to_transform] = transofermed_column\n",
    "\n",
    "#y = le.fit_transform(df1[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb194f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) use this to convert nominal labels to numerical values\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one = OneHotEncoder()\n",
    "column_to_transform = 'exemple_column'\n",
    "enc_data = one.fit_transform(df[column_to_transform].values).toarray()\n",
    "l = list(one.categories_[0])\n",
    "enc_df = pd.DataFrame(enc_data.toarray(),columns=l)\n",
    "df = df.join(enc_df)\n",
    "df = df.drop([column_to_transform],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b02ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) use this to convert ordinal labels to numerical values\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "categories = ['bad','good','very good'] # exemple of ordinal categories\n",
    "oe = OrdinalEncoder(categories=[categories],dtype=int)\n",
    "column_to_transform = 'col_name' \n",
    "df[column_to_transform] = oe.fit_transform(df[column_to_transform].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the ranges of the features to be between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_processed = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data standardization\n",
    "from sklearn.preprocessing import PowerTransformer,StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "preprocessor = make_pipeline(PowerTransformer(),StandardScaler())\n",
    "df_processed = pd.DataFrame(preprocessor.fit_transform(df),columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (OPTIONAL) DO THIS STEP ONLY IF THE DATASET HAS A LARGE NUMBER OF FEATURES (E.G. MORE THAN 20)\n",
    "# remove features with low variance, or with high correlation with other features\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_traformed = pca.fit_transform(X)\n",
    "print(f'Explained variance ratio: {pca.explained_variance_ratio_}')\n",
    "min_variance = 0.90 #or 80%\n",
    "variance_cumsum = np.cumsum(pca.explained_variance_ratio_.copy())\n",
    "cutoff_index = np.argmax(variance_cumsum>min_variance)\n",
    "X = X_traformed[:,:cutoff_index+1]\n",
    "print(f'X shape after PCA {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371dce32",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b5f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, random_state=randomState, train_size=train_size)\n",
    "print(\"Training on {} examples\".format(len(X_train)))\n",
    "print(\"Testing on {} examples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb488028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set classifier labels and their parameters for grid search\n",
    "\n",
    "model_lbls = [\n",
    "    'dt' # decision tree\n",
    "    ,'nb' # gaussian native bayers\n",
    "    ,'lp' # linear perceptron\n",
    "    # 'svm'  # we remove svm because it is too slow to train and test, and during the exam the pc could crash\n",
    "    ,'knn' # K-nearest neighbours\n",
    "    ,'adb' # adaboost\n",
    "    ,'rf' # random forest\n",
    "]\n",
    "\n",
    "\n",
    "param_dt = [{'max_depth':[*range(1,20)], 'class_weight':[None,'balanced']}]\n",
    "param_nb = [{'var_smoothing':[10**exp for exp in range(-3,-12,-1)]}]\n",
    "param_lp = [{'early_stopping':[True,False], 'class_weight':[None,'balanced']}]\n",
    "param_knn = [{'n_neighbors':[*range(2,7)]}]\n",
    "param_adb = [{'n_estimators':[10,20,30,40,50],'learning_rate':[0.5,0.75,1,1.25,1.5]}]\n",
    "param_rf = [{'n_estimators':[*range(10,30,4)], 'max_depth':[*range(4,30,4)], 'class_weight':[None,'balanced']}]\n",
    "\n",
    "# svc is very computational expensive. cosider to avoid using it during the exam to avoid computer crash\n",
    "param_svc = [\n",
    "    {'kernel':['rbf'],'gamma':[1e-3,1e-4],'C':[1,10,100]},     #C=1 prioritize the margin, C=100 prioritize the decrease of the training error\n",
    "    {'kernel':['linear'],'C':[1,10,100]}\n",
    "]\n",
    "\n",
    "models = {\n",
    "    'dt': {\n",
    "        'name': 'Decision Tree       ',\n",
    "        'estimator': DecisionTreeClassifier(random_state=randomState),\n",
    "        'param': param_dt\n",
    "    },\n",
    "    'nb': {\n",
    "        'name': 'Gaussian Naive Bayes',\n",
    "        'estimator': GaussianNB(),\n",
    "        'param': param_nb\n",
    "    },\n",
    "    'lp': {'name': 'Linear Perceptron   ',\n",
    "       'estimator': Perceptron(random_state=randomState),\n",
    "       'param': param_lp,\n",
    "    },\n",
    "  'svc':{'name': 'Support Vector',\n",
    "           'estimator': SVC(random_state=randomState), \n",
    "           'param': param_svc\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor ',\n",
    "           'estimator': KNeighborsClassifier(),\n",
    "           'param': param_knn\n",
    "       },\n",
    "    'adb':{'name': 'AdaBoost           ',\n",
    "           'estimator': AdaBoostClassifier(random_state=randomState),\n",
    "           'param': param_adb\n",
    "          },\n",
    "    'rf': {'name': 'Random forest       ',\n",
    "           'estimator': RandomForestClassifier(random_state=randomState),\n",
    "           'param': param_rf\n",
    "          }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69832500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the scoring metrics for the grid search\n",
    "scorings = ['accuracy','precision_macro','recall_macro','f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413fbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate the datastructure to store the results\n",
    "clfs = []\n",
    "results = pd.DataFrame(columns=['scoring','model','best_params','accuracy','precision_macro','recall_macro','f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc331c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the classifier with grid search, for each scoring metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for scoring in scorings:\n",
    "    for m in model_lbls:\n",
    "        clf = GridSearchCV(\n",
    "            models[m]['estimator'],\n",
    "            models[m]['param'],\n",
    "            scoring=scoring,\n",
    "            cv=cv_splits\n",
    "        )\n",
    "        clf.fit(X_train,y_train)\n",
    "        clfs.append(clf.best_estimator_)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        cr = classification_report(y_test, y_pred, output_dict=True, zero_division=1)\n",
    "        results.loc[len(results)] = [\n",
    "            scoring,\n",
    "            models[m]['name'],\n",
    "            clf.best_params_,\n",
    "            cr['accuracy'],\n",
    "            cr['macro avg']['precision'],\n",
    "            cr['macro avg']['recall'],\n",
    "            cr['macro avg']['f1-score']\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d83ea",
   "metadata": {},
   "source": [
    "## Result Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbc595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the results for each scoring metric\n",
    "for score in scorings:\n",
    "    display(\n",
    "        results[results.scoring==score]\\\n",
    "            .sort_values(by=score,ascending=False)\\\n",
    "            .drop('scoring',axis=1)\\\n",
    "            .style.format(precision=3)\\\n",
    "            .set_caption(f'Best Models for:{score}')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfec04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the confusion matrix for the best model for each scoring metric\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "for score in scorings:\n",
    "    scoring_filter = score\n",
    "    best_row = results.loc[results.scoring==scoring_filter,scoring_filter].idxmax(axis=0)\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(X=X_test, y=y_test, estimator = clfs[best_row])\n",
    "    disp.ax_.set_title(\"Best Model for {}: {}\".format(score,results.at[best_row,'model']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDM2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
